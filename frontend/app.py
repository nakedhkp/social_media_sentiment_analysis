import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import os
from wordcloud import WordCloud

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ç¤¾äº¤åª’ä½“èˆ†æƒ…åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ä¸­æ–‡å­—ä½“è®¾ç½® ---
FONT_DIR = os.path.join(os.path.dirname(__file__), 'assets')
FONT_FILENAME = 'simhei.ttf'  
FONT_PATH = os.path.join(FONT_DIR, FONT_FILENAME)

if not os.path.exists(FONT_PATH):
    st.warning(f"å­—ä½“æ–‡ä»¶ {FONT_PATH} æœªæ‰¾åˆ°ï¼Œä¸­æ–‡å¯èƒ½æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚")
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Microsoft YaHei', 'SimHei', 'DejaVu Sans']
else:
    plt.rcParams['font.sans-serif'] = [
        os.path.splitext(FONT_FILENAME)[0],
        'Arial Unicode MS', 'Microsoft YaHei', 'SimHei', 'DejaVu Sans'
    ]
plt.rcParams['axes.unicode_minus'] = False

# --- æ•°æ®åŠ è½½å‡½æ•° ---
@st.cache_data(ttl=300)
def load_simulated_data():
    try:
        sim_sentiment_dist = pd.read_csv("data/processed/sentiment_distribution.csv")
        sim_platform_sentiment = pd.read_csv("data/processed/platform_sentiment.csv")
        sim_sample_data = pd.read_csv("data/processed/sentiment_sample.csv")
        return sim_sentiment_dist, sim_platform_sentiment, sim_sample_data
    except FileNotFoundError:
        st.error("âŒ æ¨¡æ‹Ÿæ•°æ®åˆ†æç»“æœæ–‡ä»¶æœªæ‰¾åˆ°ï¼è¯·å…ˆè¿è¡Œ `python src/main.py simulation`ã€‚")
        return None, None, None
    except Exception as e:
        st.error(f"âŒ åŠ è½½æ¨¡æ‹Ÿæ•°æ®æ—¶å‡ºé”™: {e}")
        return None, None, None

@st.cache_data(ttl=300)
def load_db_analysis_data():    
    base_path = "data/processed/db_analysis"
    data_files = {
        "note_stats": "note_comment_stats.csv",
        "comment_daily_dist": "comment_daily_distribution.csv",
        "combined_sentiment_dist": "combined_sentiment_distribution.csv",
        "sentiment_over_time": "combined_sentiment_over_time.csv", # å†å²æƒ…æ„Ÿæ•°æ®
        "top_tags": "top_tags_for_wordcloud.csv",
        "sentiment_by_location": "combined_sentiment_by_location_sample.csv",
        "trend_predictions": "sentiment_trend_predictions.csv", # æ–°å¢ï¼šæƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹ç»“æœ
        "trend_evaluation": "sentiment_trend_evaluation.csv"   # æ–°å¢ï¼šè¶‹åŠ¿æ¨¡å‹è¯„ä¼°ç»“æœ
    }
    loaded_data = {}
    any_loaded = False

    for key, filename in data_files.items():
        file_path = os.path.join(base_path, filename)
        try:
            loaded_data[key] = pd.read_csv(file_path)
            any_loaded = True
        except FileNotFoundError:
            st.warning(f"æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{file_path}ã€‚å¯¹åº”å›¾è¡¨æˆ–æ•°æ®å¯èƒ½æ— æ³•æ˜¾ç¤ºã€‚")
            loaded_data[key] = pd.DataFrame() # è¿”å›ç©ºDataFrameä»¥ä¾¿åç»­æ£€æŸ¥
        except Exception as e:
            st.error(f"âŒ åŠ è½½ {filename} æ—¶å‡ºé”™: {e}")
            loaded_data[key] = pd.DataFrame()

    if not any_loaded:
        st.error("âŒ æ•°æ®åº“åˆ†æç»“æœæ–‡ä»¶å‡æœªæ‰¾åˆ°ï¼è¯·å…ˆè¿è¡Œ `python src/main.py db_sql`ã€‚")
        return None

    return loaded_data

# --- ä¸»åº”ç”¨é€»è¾‘ ---
st.title("ğŸ“Š ç¤¾äº¤åª’ä½“èˆ†æƒ…åˆ†æç³»ç»Ÿ")
st.markdown("åŸºäº PySparkã€SnowNLP å’Œ Streamlit çš„èˆ†æƒ…ç›‘æ§ä¸åˆ†æå¹³å°")

# --- ä¾§è¾¹æ  ---
st.sidebar.header("âš™ï¸ æ§åˆ¶é¢æ¿")
analysis_mode = st.sidebar.radio(
    "é€‰æ‹©åˆ†ææ¨¡å¼ï¼š",
    ('æ¨¡æ‹Ÿæ•°æ®åˆ†æ', 'æ•°æ®åº“(å°çº¢ä¹¦)åˆ†æ'),
    key="analysis_mode_selector"
)

# --- é¢œè‰²æ˜ å°„ ---
SENTIMENT_COLORS = {
    'positive': '#2E8B57',  # SeaGreen
    'negative': '#DC143C',  # Crimson
    'neutral': '#4682B4',   # SteelBlue
    'unknown': '#808080'    # Gray
}

if analysis_mode == 'æ¨¡æ‹Ÿæ•°æ®åˆ†æ':
    st.header("ğŸš€ æ¨¡æ‹Ÿæ•°æ®åˆ†æç»“æœ")
    sentiment_dist, platform_sentiment, sample_data = load_simulated_data()

    if sentiment_dist is not None and not sentiment_dist.empty:
        # æŒ‡æ ‡å¡
        col1, col2, col3, col4 = st.columns(4)
        total_posts = int(sentiment_dist['count'].sum())
        positive_posts = int(sentiment_dist.loc[sentiment_dist['sentiment_category'] == 'positive', 'count'].sum())
        negative_posts = int(sentiment_dist.loc[sentiment_dist['sentiment_category'] == 'negative', 'count'].sum())
        neutral_posts = int(sentiment_dist.loc[sentiment_dist['sentiment_category'] == 'neutral', 'count'].sum())

        col1.metric("ğŸ“ æ€»å¸–å­æ•°", f"{total_posts:,}")
        col2.metric("ğŸ˜Š ç§¯ææƒ…æ„Ÿ", f"{positive_posts:,}", f"{positive_posts/total_posts*100:.1f}%" if total_posts > 0 else "0.0%")
        col3.metric("ğŸ˜¢ æ¶ˆææƒ…æ„Ÿ", f"{negative_posts:,}", f"{negative_posts/total_posts*100:.1f}%" if total_posts > 0 else "0.0%")
        col4.metric("ğŸ˜ ä¸­æ€§æƒ…æ„Ÿ", f"{neutral_posts:,}", f"{neutral_posts/total_posts*100:.1f}%" if total_posts > 0 else "0.0%")

        # æƒ…æ„Ÿåˆ†å¸ƒå›¾å’Œæ¡å½¢å›¾
        chart_col1, chart_col2 = st.columns(2)
        with chart_col1:
            st.subheader("ğŸ­ æ•´ä½“æƒ…æ„Ÿåˆ†å¸ƒ (æ¨¡æ‹Ÿæ•°æ®)")
            fig_pie = px.pie(
                sentiment_dist,
                values='count',
                names='sentiment_category',
                color='sentiment_category',
                color_discrete_map=SENTIMENT_COLORS,
                title="æƒ…æ„Ÿç±»åˆ«å æ¯”"
            )
            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig_pie, use_container_width=True)

        with chart_col2:
            st.subheader("ğŸ“Š æƒ…æ„Ÿç±»åˆ«ç»Ÿè®¡ (æ¨¡æ‹Ÿæ•°æ®)")
            fig_bar = px.bar(
                sentiment_dist.sort_values('count', ascending=True),
                x='count',
                y='sentiment_category',
                orientation='h',
                color='sentiment_category',
                color_discrete_map=SENTIMENT_COLORS,
                title="å„ç±»åˆ«å¸–å­æ•°é‡"
            )
            fig_bar.update_layout(showlegend=False)
            st.plotly_chart(fig_bar, use_container_width=True)

        # å„å¹³å°æƒ…æ„Ÿçƒ­åŠ›å›¾
        if platform_sentiment is not None and not platform_sentiment.empty:
            st.subheader("ğŸ“± å„å¹³å°æƒ…æ„Ÿåˆ†æ (æ¨¡æ‹Ÿæ•°æ®)")
            if {'platform', 'sentiment_category', 'count'}.issubset(platform_sentiment.columns):
                try:
                    platform_pivot = platform_sentiment.pivot_table(
                        index='platform',
                        columns='sentiment_category',
                        values='count',
                        fill_value=0
                    )
                    fig_heatmap = px.imshow(
                        platform_pivot,
                        color_continuous_scale='RdYlGn',
                        title="å„å¹³å°æƒ…æ„Ÿåˆ†å¸ƒçƒ­åŠ›å›¾"
                    )
                    fig_heatmap.update_xaxes(title="æƒ…æ„Ÿç±»åˆ«")
                    fig_heatmap.update_yaxes(title="å¹³å°")
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¹³å°æƒ…æ„Ÿçƒ­åŠ›å›¾æ—¶å‡ºé”™: {e}")
                    st.dataframe(platform_sentiment)
            else:
                st.info("å¹³å°æƒ…æ„Ÿæ•°æ®åˆ—ä¸å®Œæ•´ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾ã€‚")

        # è¯¦ç»†æ ·æœ¬å±•ç¤º
        if sample_data is not None and not sample_data.empty:
            st.subheader("ğŸ“‹ è¯¦ç»†åˆ†æç»“æœ (æ¨¡æ‹Ÿæ•°æ®æ ·æœ¬)")
            sentiments_sim = ["å…¨éƒ¨"] + list(sample_data['sentiment_category'].unique())
            sentiment_filter_sim = st.selectbox("é€‰æ‹©æƒ…æ„Ÿç±»åˆ« (æ¨¡æ‹Ÿ)", sentiments_sim, key="sim_sentiment_filter")

            platform_exists_sim = 'platform' in sample_data.columns
            platforms_sim = ["å…¨éƒ¨"] + list(sample_data['platform'].unique()) if platform_exists_sim else ["å…¨éƒ¨"]
            platform_filter_sim = st.selectbox(
                "é€‰æ‹©å¹³å° (æ¨¡æ‹Ÿ)", platforms_sim, key="sim_platform_filter",
                disabled=not platform_exists_sim
            )

            filtered_sim = sample_data.copy()
            if sentiment_filter_sim != "å…¨éƒ¨":
                filtered_sim = filtered_sim[filtered_sim['sentiment_category'] == sentiment_filter_sim]
            if platform_filter_sim != "å…¨éƒ¨" and platform_exists_sim:
                filtered_sim = filtered_sim[filtered_sim['platform'] == platform_filter_sim]

            st.write(f"å…± {len(filtered_sim)} æ¡è®°å½•")
            display_cols_sim = ['text', 'sentiment_score', 'sentiment_category']
            if platform_exists_sim:
                display_cols_sim.append('platform')
            st.dataframe(filtered_sim[display_cols_sim], height=300, use_container_width=True)
        else:
            st.info("æ¨¡æ‹Ÿæ•°æ®æ ·æœ¬ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ã€‚")
    else:
        st.info("æ¨¡æ‹Ÿæ•°æ®åˆ†æç»“æœä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ã€‚")

elif analysis_mode == 'æ•°æ®åº“(å°çº¢ä¹¦)åˆ†æ':
    st.header("ğŸ’¾ æ•°æ®åº“ (å°çº¢ä¹¦) åˆ†æç»“æœ")
    db_data = load_db_analysis_data()

    if db_data:
        # --- è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ ---
        st.subheader("ğŸ’¬ ç¬”è®°+è¯„è®º æ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒ")
        combined_sentiment_dist = db_data.get("combined_sentiment_dist")
        if combined_sentiment_dist is not None and not combined_sentiment_dist.empty:
            fig_pie_db = px.pie(
                combined_sentiment_dist,
                values='count',
                names='sentiment_category',
                color='sentiment_category',
                color_discrete_map=SENTIMENT_COLORS,
                title="ç¬”è®°+è¯„è®º æƒ…æ„Ÿç±»åˆ«å æ¯”"
            )
            fig_pie_db.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig_pie_db, use_container_width=True)
        else:
            st.info("æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ã€‚")

        # --- æƒ…æ„Ÿè¶‹åŠ¿å˜åŒ– (å†å²æ•°æ®) ---
        st.subheader("ğŸ“ˆ å†å²æƒ…æ„Ÿè¶‹åŠ¿å˜åŒ– (æŒ‰æ—¥ï¼Œç¬”è®°+è¯„è®º)")
        sentiment_over_time_hist = db_data.get("sentiment_over_time")
        if sentiment_over_time_hist is not None and not sentiment_over_time_hist.empty and 'date' in sentiment_over_time_hist.columns:
            sentiment_over_time_hist['date'] = pd.to_datetime(sentiment_over_time_hist['date'])
            sentiment_over_time_hist = sentiment_over_time_hist.sort_values('date')
            try:
                hist_trend_pivot = sentiment_over_time_hist.pivot_table(
                    index='date',
                    columns='sentiment_category',
                    values='count',
                    fill_value=0
                ).reset_index()
                fig_hist_trend = go.Figure()
                for sentiment_cat in SENTIMENT_COLORS.keys():
                    if sentiment_cat in hist_trend_pivot.columns:
                        fig_hist_trend.add_trace(go.Scatter(
                            x=hist_trend_pivot['date'],
                            y=hist_trend_pivot[sentiment_cat],
                            mode='lines+markers',
                            name=f"å†å² {sentiment_cat}",
                            marker_color=SENTIMENT_COLORS[sentiment_cat]
                        ))
                fig_hist_trend.update_layout(
                    title='æ¯æ—¥æƒ…æ„Ÿæ•°é‡å†å²å˜åŒ– (ç¬”è®° + è¯„è®º)',
                    xaxis_title='æ—¥æœŸ',
                    yaxis_title='æ•°é‡',
                    legend_title_text='æƒ…æ„Ÿç±»åˆ«'
                )
                st.plotly_chart(fig_hist_trend, use_container_width=True)
            except Exception as e:
                st.error(f"ç»˜åˆ¶å†å²æƒ…æ„Ÿè¶‹åŠ¿å›¾æ—¶å‡ºé”™: {e}")
                st.dataframe(sentiment_over_time_hist)
        else:
            st.info("å†å²è¶‹åŠ¿å˜åŒ–æ•°æ®ä¸ºç©ºã€åŠ è½½å¤±è´¥æˆ–ç¼ºå°‘ 'date' åˆ—ã€‚")

        # --- æƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹ ---
        st.subheader("ğŸ”® æœªæ¥æƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹")
        trend_predictions = db_data.get("trend_predictions")
        trend_evaluation = db_data.get("trend_evaluation")

        if trend_predictions is not None and not trend_predictions.empty and 'date' in trend_predictions.columns and 'predicted_sentiment' in trend_predictions.columns:
            trend_predictions['date'] = pd.to_datetime(trend_predictions['date'])
            trend_predictions = trend_predictions.sort_values('date')

            # åˆ›å»ºé¢„æµ‹è¶‹åŠ¿å›¾
            fig_pred_trend = go.Figure()
            
            # æ·»åŠ é¢„æµ‹çº¿
            fig_pred_trend.add_trace(go.Scatter(
                x=trend_predictions['date'],
                y=trend_predictions['predicted_sentiment'],
                mode='lines+markers',
                name='é¢„æµ‹æƒ…æ„Ÿå€¼',
                line=dict(color='royalblue', dash='dash'),
                marker=dict(size=8)
            ))
            
            # å¦‚æœæœ‰å…¶ä»–é¢„æµ‹æŒ‡æ ‡ï¼Œä¹Ÿæ·»åŠ åˆ°å›¾ä¸­
            if 'post_count' in trend_predictions.columns:
                fig_pred_trend.add_trace(go.Scatter(
                    x=trend_predictions['date'],
                    y=trend_predictions['post_count'],
                    mode='lines',
                    name='é¢„æµ‹å¸–å­æ•°',
                    line=dict(color='green', dash='dot'),
                    yaxis='y2'
                ))
            
            # æ›´æ–°å¸ƒå±€
            fig_pred_trend.update_layout(
                title='æœªæ¥æƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹',
                xaxis_title='é¢„æµ‹æ—¥æœŸ',
                yaxis_title='é¢„æµ‹æƒ…æ„Ÿå¹³å‡åˆ†',
                yaxis2=dict(
                    title='é¢„æµ‹å¸–å­æ•°',
                    overlaying='y',
                    side='right'
                ),
                legend_title_text='é¢„æµ‹æŒ‡æ ‡',
                hovermode='x unified'
            )
            
            st.plotly_chart(fig_pred_trend, use_container_width=True)

            # --- é¢„æµ‹æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ ---
            if trend_evaluation is not None and not trend_evaluation.empty:
                st.markdown("#### ğŸ“ˆ é¢„æµ‹æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ (æµ‹è¯•é›†)")
                eval_metrics = trend_evaluation.iloc[0].to_dict()
                
                # åˆ›å»ºè¯„ä¼°æŒ‡æ ‡å¡ç‰‡
                cols_eval = st.columns(len(eval_metrics))
                for i, (metric, value) in enumerate(eval_metrics.items()):
                    if isinstance(value, float):
                        # æ ¹æ®æŒ‡æ ‡ç±»å‹è®¾ç½®ä¸åŒçš„é¢œè‰²
                        if metric.lower() in ['rmse', 'mae']:
                            delta_color = 'inverse'  # è¶Šå°è¶Šå¥½
                        else:
                            delta_color = 'normal'   # è¶Šå¤§è¶Šå¥½
                            
                        cols_eval[i].metric(
                            label=metric.upper(),
                            value=f"{value:.4f}",
                            delta_color=delta_color
                        )
                    else:
                        cols_eval[i].metric(
                            label=metric.upper(),
                            value=str(value)
                        )
                
                # æ·»åŠ é¢„æµ‹ç»“æœè¯´æ˜
                st.markdown("""
                **é¢„æµ‹ç»“æœè¯´æ˜ï¼š**
                - RMSE (å‡æ–¹æ ¹è¯¯å·®): é¢„æµ‹å€¼ä¸å®é™…å€¼çš„å¹³å‡åå·®ï¼Œè¶Šå°è¶Šå¥½
                - MAE (å¹³å‡ç»å¯¹è¯¯å·®): é¢„æµ‹å€¼ä¸å®é™…å€¼çš„å¹³å‡ç»å¯¹åå·®ï¼Œè¶Šå°è¶Šå¥½
                - RÂ² (å†³å®šç³»æ•°): æ¨¡å‹è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½
                """)
            else:
                st.info("é¢„æµ‹æ¨¡å‹è¯„ä¼°æ•°æ®ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ã€‚")
        else:
            st.info("æƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹æ•°æ®ä¸ºç©ºã€åŠ è½½å¤±è´¥æˆ–åˆ—åä¸æ­£ç¡® (éœ€è¦ 'date' å’Œ 'predicted_sentiment')ã€‚")

        # --- è¯„è®ºå†…å®¹è¯äº‘å›¾ï¼ˆæ”¹ä¸ºæ ‡ç­¾è¯äº‘ï¼‰ ---
        st.subheader("â˜ï¸ çƒ­é—¨æ ‡ç­¾è¯äº‘å›¾")
        top_tags = db_data.get("top_tags")
        if top_tags is not None and not top_tags.empty and {'tag', 'tag_count'}.issubset(top_tags.columns):
            # æ„å»ºè¯é¢‘å­—å…¸
            tag_freq = dict(zip(top_tags['tag'], top_tags['tag_count']))
            if tag_freq:
                try:
                    if not os.path.exists(FONT_PATH):
                        st.error(f"è¯äº‘å­—ä½“ {FONT_PATH} æœªæ‰¾åˆ°ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘å›¾ã€‚")
                    else:
                        wc = WordCloud(
                            font_path=FONT_PATH,
                            width=800,
                            height=400,
                            background_color='white',
                            stopwords=set(),  # æ ‡ç­¾é€šå¸¸ä¸éœ€è¦åœç”¨è¯è¿‡æ»¤
                            collocations=False
                        )
                        wordcloud_image = wc.generate_from_frequencies(tag_freq)
                        fig_wc, ax_wc = plt.subplots(figsize=(12, 6))
                        ax_wc.imshow(wordcloud_image, interpolation='bilinear')
                        ax_wc.axis('off')
                        st.pyplot(fig_wc)
                except Exception as e:
                    st.error(f"ç”Ÿæˆæ ‡ç­¾è¯äº‘å›¾æ—¶å‡ºé”™: {e}")
            else:
                st.info("çƒ­é—¨æ ‡ç­¾æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯äº‘å›¾ã€‚")
        else:
            st.info("çƒ­é—¨æ ‡ç­¾æ•°æ®ç¼ºå¤±æˆ–åˆ—åä¸æ­£ç¡®ã€‚")

        # --- çƒ­é—¨ç¬”è®°æ ‡ç­¾æŸ±çŠ¶å›¾ ---
        st.subheader("ğŸ·ï¸ çƒ­é—¨ç¬”è®°æ ‡ç­¾ç»Ÿè®¡")
        if top_tags is not None and not top_tags.empty and {'tag', 'tag_count'}.issubset(top_tags.columns):
            max_show = min(50, len(top_tags))
            num_tags_to_show = st.slider(
                "é€‰æ‹©æ˜¾ç¤ºæ ‡ç­¾æ•°é‡:",
                5,
                max_show,
                10,
                key="tags_slider_db"
            )
            fig_tags = px.bar(
                top_tags.head(num_tags_to_show).sort_values('tag_count', ascending=True),
                x='tag_count',
                y='tag',
                orientation='h',
                title=f"Top {num_tags_to_show} ç¬”è®°æ ‡ç­¾",
                labels={'tag_count': 'å‡ºç°æ¬¡æ•°', 'tag': 'æ ‡ç­¾'},
                color='tag_count',
                color_continuous_scale=px.colors.sequential.Viridis
            )
            st.plotly_chart(fig_tags, use_container_width=True)
        else:
            st.info("çƒ­é—¨æ ‡ç­¾æ•°æ®ä¸ºç©ºã€åŠ è½½å¤±è´¥æˆ–åˆ—åä¸æ­£ç¡®ã€‚")

        # --- è¯„è®ºæŒ‰å¤©åˆ†å¸ƒ ---
        st.subheader("ğŸ—“ï¸ è¯„è®ºæŒ‰å¤©åˆ†å¸ƒ")
        comment_daily_dist = db_data.get("comment_daily_dist")
        if comment_daily_dist is not None and not comment_daily_dist.empty and 'comment_date' in comment_daily_dist.columns:
            comment_daily_dist['comment_date'] = pd.to_datetime(comment_daily_dist['comment_date'])
            fig_daily = px.bar(
                comment_daily_dist.sort_values('comment_date'),
                x='comment_date',
                y='num_comments',
                title='æ¯æ—¥è¯„è®ºæ•°',
                labels={'comment_date': 'æ—¥æœŸ', 'num_comments': 'è¯„è®ºæ•°é‡'},
                color='num_comments',
                color_continuous_scale='Blues'
            )
            st.plotly_chart(fig_daily, use_container_width=True)
        else:
            st.info("è¯„è®ºæŒ‰å¤©åˆ†å¸ƒæ•°æ®ä¸ºç©ºã€åŠ è½½å¤±è´¥æˆ–ç¼ºå°‘ 'comment_date' åˆ—ã€‚")

        # --- è¯„è®ºåœ°ç†ä½ç½®æƒ…æ„Ÿåˆ†å¸ƒ ---
        st.subheader("ğŸŒ è¯„è®ºåœ°ç†ä½ç½®æƒ…æ„Ÿåˆ†å¸ƒ (æŠ½æ ·)")
        sentiment_by_location = db_data.get("sentiment_by_location")
        if sentiment_by_location is not None and not sentiment_by_location.empty and \
           {'ip_location', 'sentiment_category', 'count'}.issubset(sentiment_by_location.columns):

            geo_sentiment_filter = st.selectbox(
                "é€‰æ‹©æƒ…æ„Ÿç±»åˆ«æŸ¥çœ‹åœ°ç†åˆ†å¸ƒ:",
                ["å…¨éƒ¨"] + list(sentiment_by_location['sentiment_category'].unique()),
                key="geo_sentiment_filter_db"
            )

            geo_data = sentiment_by_location.copy()
            if geo_sentiment_filter != "å…¨éƒ¨":
                geo_data = geo_data[geo_data['sentiment_category'] == geo_sentiment_filter]

            if not geo_data.empty:
                location_summary = geo_data.groupby('ip_location')['count'].sum().reset_index()
                location_summary = location_summary.sort_values('count', ascending=False)

                max_locations = min(20, len(location_summary))
                top_n_locations = st.slider(
                    "æ˜¾ç¤ºè¯„è®ºæœ€å¤šçš„åœ°åŒºæ•°é‡:",
                    3,
                    max_locations,
                    10,
                    key="geo_loc_slider_db"
                )

                top_locations = location_summary.head(top_n_locations)['ip_location'].tolist()
                filtered_geo_plot = geo_data[geo_data['ip_location'].isin(top_locations)]

                if not filtered_geo_plot.empty:
                    title_geo = f"Top {top_n_locations} åœ°åŒºè¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ"
                    if geo_sentiment_filter != "å…¨éƒ¨":
                        title_geo += f" ({geo_sentiment_filter})"

                    fig_geo = px.bar(
                        filtered_geo_plot,
                        x='ip_location',
                        y='count',
                        color='sentiment_category' if geo_sentiment_filter == "å…¨éƒ¨" else None,
                        color_discrete_map=SENTIMENT_COLORS if geo_sentiment_filter == "å…¨éƒ¨" else None,
                        barmode='stack',
                        title=title_geo,
                        labels={'ip_location': 'åœ°åŒº (IPå±åœ°)', 'count': 'è¯„è®ºæ•°é‡', 'sentiment_category': 'æƒ…æ„Ÿç±»åˆ«'}
                    )
                    fig_geo.update_xaxes(categoryorder='total descending')
                    st.plotly_chart(fig_geo, use_container_width=True)
                else:
                    st.info(f'åœ¨ Top{top_n_locations} åœ°åŒºä¸­ï¼Œæ—  "{geo_sentiment_filter}" ç±»åˆ«æ•°æ®ã€‚')
            else:
                st.info(f'æ²¡æœ‰ "{geo_sentiment_filter}" ç±»åˆ«çš„è¯„è®ºæ•°æ®ã€‚')

            st.markdown(
                "<small>*æ³¨æ„ï¼šåœ°ç†åˆ†å¸ƒä»…æ ¹æ®IPå±åœ°å­—ç¬¦ä¸²ç»Ÿè®¡ã€‚å¦‚éœ€åœ°å›¾å¯è§†åŒ–ï¼Œåº”å°†çœä»½è½¬æ¢ä¸ºç»çº¬åº¦ï¼Œ"
                "å¯å€ŸåŠ©åœ°ç†ç¼–ç æœåŠ¡ã€‚*</small>",
                unsafe_allow_html=True
            )
        else:
            st.info("åœ°ç†æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®ä¸ºç©ºæˆ–ä¸å®Œæ•´ï¼Œæ— æ³•æ¸²æŸ“å›¾è¡¨ã€‚")

        # --- ç¬”è®°ç‚¹èµ/è¯„è®ºç»Ÿè®¡è¡¨ ---
        st.subheader("ğŸ“ ç¬”è®°ç‚¹èµ & è¯„è®ºç»Ÿè®¡ (ç¬”è®°è¡¨ vs è¯„è®ºè¡¨)")
        note_stats = db_data.get("note_stats")
        if note_stats is not None and not note_stats.empty:
            st.dataframe(
                note_stats[['note_id', 'title', 'liked_count', 'note_declared_comment_count', 'actual_comment_count']].head(20),
                height=300,
                use_container_width=True
            )
        else:
            st.info("ç¬”è®°ç»Ÿè®¡æ•°æ®ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ã€‚")
    else:
        st.info("æ•°æ®åº“åˆ†ææ•°æ®åŠ è½½å¤±è´¥ã€‚è¯·ç¡®ä¿å·²è¿è¡Œ `python src/main.py db_sql` å¹¶ç”Ÿæˆç»“æœæ–‡ä»¶ã€‚")

# --- ä½¿ç”¨è¯´æ˜ ---
with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
    st.markdown(f"""
    ### å¦‚ä½•ä½¿ç”¨æœ¬ç³»ç»Ÿï¼š

    1. **ç¯å¢ƒå‡†å¤‡ï¼š**
       - ç¡®ä¿å·²å®‰è£…å¹¶å¯åŠ¨ MySQL æ•°æ®åº“ã€‚
       - ä½¿ç”¨é¡¹ç›®æä¾›çš„ SQL è„šæœ¬åˆ›å»º `xhs_note` å’Œ `xhs_note_comment` è¡¨ï¼Œå¹¶å¯¼å…¥æµ‹è¯•æ•°æ®ã€‚
       - åœ¨ `config/config.ini` ä¸­é…ç½®å¥½ä½ çš„ MySQL è¿æ¥ä¿¡æ¯ã€‚
       - è¯·å°†ä¸­æ–‡å­—ä½“æ–‡ä»¶ï¼ˆå¦‚ `simhei.ttf`ã€`msyh.ttc`ï¼‰æ”¾åˆ° `frontend/assets/` ç›®å½•ï¼Œå¹¶ç¡®ä¿ `FONT_PATH` æŒ‡å‘è¯¥æ–‡ä»¶ï¼Œä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤ºã€‚

    2. **å®‰è£…ä¾èµ–ï¼š**
       ```bash
       pip install -r requirements.txt
       ```

    3. **è¿è¡Œåˆ†æè„šæœ¬ (`src/main.py`)ï¼š**
       - **æ¨¡æ‹Ÿæ•°æ®åˆ†æï¼š**
         ```bash
         python src/main.py simulation
         ```
       - **æ•°æ®åº“(å°çº¢ä¹¦)åˆ†æ (åŒ…å«æƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹)ï¼š**
         ```bash
         python src/main.py db_sql
         ```
       åˆ†æå®Œæˆåï¼Œä¼šåœ¨ `data/processed/`ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰æˆ–
       `data/processed/db_analysis/`ï¼ˆæ•°æ®åº“ï¼‰ä¸‹ç”Ÿæˆå¯¹åº” CSV æ–‡ä»¶ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿè¶‹åŠ¿é¢„æµ‹å’Œè¯„ä¼°ç»“æœã€‚

    4. **å¯åŠ¨å‰ç«¯åº”ç”¨ï¼š**
       ```bash
       streamlit run frontend/app.py
       ```
       æ‰“å¼€æµè§ˆå™¨ï¼Œåœ¨ä¾§è¾¹æ é€‰æ‹©"æ¨¡æ‹Ÿæ•°æ®åˆ†æ"æˆ–"æ•°æ®åº“(å°çº¢ä¹¦)åˆ†æ"æŸ¥çœ‹ç»“æœã€‚

    ### åŠŸèƒ½äº®ç‚¹ï¼š
    - ä½¿ç”¨ PySpark è¿›è¡Œæµ·é‡æ•°æ®æ¸…æ´—ä¸èšåˆã€‚
    - åŸºäº SnowNLP å¯¹ä¸­æ–‡æ–‡æœ¬åšæƒ…æ„Ÿæ‰“åˆ†ä¸åˆ†ç±»ã€‚
    - **æ–°å¢ï¼š** ä½¿ç”¨ `EnhancedSentimentTrendPredictor` æ¨¡å—å¯¹æƒ…æ„Ÿè¶‹åŠ¿è¿›è¡Œé¢„æµ‹ï¼Œå¹¶å±•ç¤ºé¢„æµ‹ç»“æœä¸æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ã€‚
    - å¯è§†åŒ–æ•´ä½“æƒ…æ„Ÿåˆ†å¸ƒã€æŒ‰æ—¥è¶‹åŠ¿ã€çƒ­é—¨æ ‡ç­¾ã€åœ°ç†æƒ…æ„Ÿåˆ†å¸ƒç­‰ã€‚
    - æ”¯æŒä¸­æ–‡è¯äº‘å±•ç¤ºçƒ­é—¨ç¬”è®°æ ‡ç­¾ã€‚
    """)

st.markdown("---")
st.markdown("ğŸ’¡ **ç¤¾äº¤åª’ä½“èˆ†æƒ…åˆ†æç³»ç»Ÿ** | æ„å»ºå·¥å…·ï¼šPySpark + SnowNLP + MySQL + Streamlit")
